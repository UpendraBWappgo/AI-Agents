{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rocky/rocky/CrewAI/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY=\"AIzaSyDT0cwIYWP5Ja0IxwLWlGTMrWhImm7KzQ8\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def sort_list(list_to_sort):\n",
      "  \"\"\"\n",
      "  Sorts a list in ascending order.\n",
      "\n",
      "  Args:\n",
      "    list_to_sort: The list to be sorted.\n",
      "\n",
      "  Returns:\n",
      "    The sorted list.\n",
      "  \"\"\"\n",
      "\n",
      "  return sorted(list_to_sort)\n",
      "\n",
      "# Example usage\n",
      "my_list = [5, 2, 8, 1, 9]\n",
      "sorted_list = sort_list(my_list)\n",
      "print(f\"Original list: {my_list}\")\n",
      "print(f\"Sorted list: {sorted_list}\")\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. **`sort_list(list_to_sort)` function:**\n",
      "   - Takes a list as input (`list_to_sort`).\n",
      "   - Uses the built-in `sorted()` function to sort the list in ascending order.\n",
      "   - Returns the sorted list.\n",
      "\n",
      "2. **Example Usage:**\n",
      "   - Creates a sample list `my_list`.\n",
      "   - Calls the `sort_list()` function to sort the list.\n",
      "   - Prints both the original and sorted lists.\n",
      "\n",
      "**Output:**\n",
      "\n",
      "```\n",
      "Original list: [5, 2, 8, 1, 9]\n",
      "Sorted list: [1, 2, 5, 8, 9]\n",
      "```\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "- **`sorted()` function:** The `sorted()` function is a built-in Python function that returns a new sorted list without modifying the original list.\n",
      "- **Ascending Order:** By default, `sorted()` sorts in ascending order.\n",
      "- **Modifying the Original List:** If you want to modify the original list in place, use the `list.sort()` method instead.\n",
      "\n",
      "**Further Customization:**\n",
      "\n",
      "- **Descending Order:** To sort in descending order, pass `reverse=True` as an argument to `sorted()`: `sorted(list_to_sort, reverse=True)`\n",
      "- **Custom Sorting Logic:** You can provide a custom comparison function to `sorted()` to define a specific sorting order.\n",
      "\n",
      "Let me know if you need more examples or want to explore other sorting techniques!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(\"Give me python code to sort a list\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Gemini\ncallback_manager\n  Plain typing.TypeAlias is not valid as type argument (type=type_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemini\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gemini\n\u001b[0;32m----> 3\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mGemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/gemini-1.5-flash-001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAIzaSyDT0cwIYWP5Ja0IxwLWlGTMrWhImm7KzQ8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m     \n",
      "File \u001b[0;32m~/rocky/CrewAI/venv/lib/python3.10/site-packages/llama_index/llms/gemini/base.py:161\u001b[0m, in \u001b[0;36mGemini.__init__\u001b[0;34m(self, api_key, model, temperature, max_tokens, generation_config, safety_settings, callback_manager, api_base, transport, model_name, default_headers, **generate_kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_tokens, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_meta\u001b[38;5;241m.\u001b[39moutput_token_limit)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rocky/CrewAI/venv/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Gemini\ncallback_manager\n  Plain typing.TypeAlias is not valid as type argument (type=type_error)"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "llm = Gemini(model=\"models/gemini-1.5-flash-001\",api_key=\"AIzaSyDT0cwIYWP5Ja0IxwLWlGTMrWhImm7KzQ8\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
